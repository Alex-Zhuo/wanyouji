#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Mall new_info æ¥å£ 10000å¹¶å‘å‹åŠ›æµ‹è¯•è„šæœ¬
ä¸“é—¨é’ˆå¯¹ /api/users/new_info/ æ¥å£è¿›è¡Œé«˜å¹¶å‘å‹åŠ›æµ‹è¯•
"""

import time
import json
import random
import threading
import statistics
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
import logging
import argparse
import sys
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('new_info_load_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    url: str
    method: str
    status_code: int
    response_time: float
    success: bool
    error_message: str = ""
    timestamp: float = 0.0
    user_id: str = ""
    share_code: str = ""


@dataclass
class TestSummary:
    """æµ‹è¯•æ±‡æ€»æ•°æ®ç±»"""
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float
    success_rate: float
    error_distribution: Dict[str, int]
    response_time_distribution: Dict[str, int]


class NewInfoLoadTester:
    """new_infoæ¥å£ä¸“ç”¨è´Ÿè½½æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str, auth_tokens: List[str] = None):
        """
        åˆå§‹åŒ–è´Ÿè½½æµ‹è¯•å™¨
        
        Args:
            base_url: APIåŸºç¡€URL
            auth_tokens: è®¤è¯tokenåˆ—è¡¨ï¼Œç”¨äºæ¨¡æ‹Ÿä¸åŒç”¨æˆ·
        """
        self.base_url = base_url.rstrip('/')
        self.auth_tokens = auth_tokens or []
        self.sessions: List[requests.Session] = []
        self.results: List[TestResult] = []
        self.lock = threading.Lock()
        
        # åˆå§‹åŒ–å¤šä¸ªsessionï¼Œæ¯ä¸ªå¯¹åº”ä¸€ä¸ªtoken
        for token in self.auth_tokens:
            session = requests.Session()
            session.headers.update({
                'Authorization': f'Bearer {token}',
                'Content-Type': 'application/json',
                'User-Agent': 'LoadTest/1.0'
            })
            self.sessions.append(session)
        
        # å¦‚æœæ²¡æœ‰æä¾›tokenï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤session
        if not self.auth_tokens:
            default_session = requests.Session()
            default_session.headers.update({
                'Content-Type': 'application/json',
                'User-Agent': 'LoadTest/1.0'
            })
            self.sessions.append(default_session)
    
    def _get_random_session(self) -> requests.Session:
        """è·å–éšæœºçš„session"""
        return random.choice(self.sessions)
    
    def _generate_share_codes(self) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•ç”¨çš„åˆ†äº«ç """
        # ç”Ÿæˆä¸€äº›æ¨¡æ‹Ÿçš„åˆ†äº«ç 
        share_codes = [
            "ABC123", "DEF456", "GHI789", "JKL012", "MNO345",
            "PQR678", "STU901", "VWX234", "YZA567", "BCD890",
            "EFG123", "HIJ456", "KLM789", "NOP012", "QRS345",
            "TUV678", "WXY901", "ZAB234", "CDE567", "FGH890"
        ]
        return share_codes
    
    def _make_request(self, user_id: str = None, share_code: str = None) -> TestResult:
        """
        å‘é€å•ä¸ªnew_infoè¯·æ±‚å¹¶è®°å½•ç»“æœ
        
        Args:
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºæ ‡è¯†ï¼‰
            share_code: å¯é€‰çš„åˆ†äº«ç å‚æ•°
            
        Returns:
            TestResult: æµ‹è¯•ç»“æœ
        """
        endpoint = '/users/new_info/'
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        params = {}
        if share_code:
            params['share_code'] = share_code
        
        try:
            # éšæœºé€‰æ‹©ä¸€ä¸ªsession
            session = self._get_random_session()
            
            # å‘é€GETè¯·æ±‚
            response = session.get(url, params=params, timeout=30)
            response_time = time.time() - start_time
            
            result = TestResult(
                url=url,
                method='GET',
                status_code=response.status_code,
                response_time=response_time,
                success=200 <= response.status_code < 300,
                timestamp=start_time,
                user_id=user_id or "unknown",
                share_code=share_code or ""
            )
            
        except requests.exceptions.RequestException as e:
            response_time = time.time() - start_time
            result = TestResult(
                url=url,
                method='GET',
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                timestamp=start_time,
                user_id=user_id or "unknown",
                share_code=share_code or ""
            )
        
        return result
    
    def _record_result(self, result: TestResult):
        """è®°å½•æµ‹è¯•ç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.lock:
            self.results.append(result)
    
    def concurrent_test(self, concurrent_users: int = 10000, 
                       total_requests: int = 50000,
                       share_code_ratio: float = 0.3) -> TestSummary:
        """
        å¹¶å‘æµ‹è¯• - æ”¯æŒ10000å¹¶å‘ç”¨æˆ·
        
        Args:
            concurrent_users: å¹¶å‘ç”¨æˆ·æ•°
            total_requests: æ€»è¯·æ±‚æ•°
            share_code_ratio: ä½¿ç”¨åˆ†äº«ç çš„è¯·æ±‚æ¯”ä¾‹
            
        Returns:
            TestSummary: æµ‹è¯•æ±‡æ€»
        """
        logger.info(f"ğŸš€ å¼€å§‹10000å¹¶å‘æµ‹è¯•: new_infoæ¥å£")
        logger.info(f"å¹¶å‘ç”¨æˆ·æ•°: {concurrent_users:,}")
        logger.info(f"æ€»è¯·æ±‚æ•°: {total_requests:,}")
        logger.info(f"åˆ†äº«ç ä½¿ç”¨æ¯”ä¾‹: {share_code_ratio:.1%}")
        
        start_time = time.time()
        share_codes = self._generate_share_codes()
        
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = []
            
            for i in range(total_requests):
                # å†³å®šæ˜¯å¦ä½¿ç”¨åˆ†äº«ç 
                use_share_code = random.random() < share_code_ratio
                share_code = random.choice(share_codes) if use_share_code else None
                
                # ç”Ÿæˆç”¨æˆ·ID
                user_id = f"user_{i % 1000:04d}"
                
                future = executor.submit(
                    self._make_request, user_id, share_code
                )
                futures.append(future)
                
                # æ¯1000ä¸ªè¯·æ±‚æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 1000 == 0:
                    logger.info(f"å·²æäº¤ {i + 1:,} ä¸ªè¯·æ±‚...")
            
            logger.info("æ‰€æœ‰è¯·æ±‚å·²æäº¤ï¼Œç­‰å¾…å®Œæˆ...")
            
            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(futures):
                result = future.result()
                self._record_result(result)
                completed += 1
                
                # æ¯1000ä¸ªå®Œæˆæ˜¾ç¤ºè¿›åº¦
                if completed % 1000 == 0:
                    logger.info(f"å·²å®Œæˆ {completed:,} ä¸ªè¯·æ±‚...")
        
        total_time = time.time() - start_time
        
        logger.info(f"âœ… æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {total_time:.2f}ç§’")
        return self._calculate_summary(total_time)
    
    def stress_test(self, initial_users: int = 1000, max_users: int = 10000,
                   step_users: int = 1000, step_duration: int = 60,
                   share_code_ratio: float = 0.3) -> List[TestSummary]:
        """
        å‹åŠ›æµ‹è¯• - é€æ­¥å¢åŠ è´Ÿè½½åˆ°10000å¹¶å‘
        
        Args:
            initial_users: åˆå§‹å¹¶å‘ç”¨æˆ·æ•°
            max_users: æœ€å¤§å¹¶å‘ç”¨æˆ·æ•°
            step_users: æ¯æ­¥å¢åŠ çš„å¹¶å‘ç”¨æˆ·æ•°
            step_duration: æ¯æ­¥æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            share_code_ratio: ä½¿ç”¨åˆ†äº«ç çš„è¯·æ±‚æ¯”ä¾‹
            
        Returns:
            List[TestSummary]: æ¯æ­¥çš„æµ‹è¯•æ±‡æ€»
        """
        logger.info(f"ğŸ”¥ å¼€å§‹å‹åŠ›æµ‹è¯•: é€æ­¥å¢åŠ åˆ°{max_users:,}å¹¶å‘ç”¨æˆ·")
        
        summaries = []
        current_users = initial_users
        
        while current_users <= max_users:
            logger.info(f"å½“å‰å¹¶å‘ç”¨æˆ·æ•°: {current_users:,}")
            
            # æ¸…ç©ºä¹‹å‰çš„ç»“æœ
            self.results.clear()
            
            # æ‰§è¡Œå½“å‰å¹¶å‘çº§åˆ«çš„æµ‹è¯•
            start_time = time.time()
            self.concurrent_test(current_users, current_users * 2, share_code_ratio)
            
            # ç­‰å¾…æŒ‡å®šæ—¶é—´
            elapsed = time.time() - start_time
            if elapsed < step_duration:
                time.sleep(step_duration - elapsed)
            
            # è®¡ç®—å½“å‰æ­¥éª¤çš„æ±‡æ€»
            summary = self._calculate_summary(step_duration)
            summaries.append(summary)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ€§èƒ½é˜ˆå€¼
            if summary.success_rate < 0.95 or summary.avg_response_time > 3.0:
                logger.warning(f"âš ï¸ æ€§èƒ½é˜ˆå€¼è¢«è§¦å‘ï¼Œåœæ­¢å¢åŠ è´Ÿè½½")
                logger.warning(f"æˆåŠŸç‡: {summary.success_rate:.2%}, å¹³å‡å“åº”æ—¶é—´: {summary.avg_response_time:.3f}ç§’")
                break
            
            current_users += step_users
        
        return summaries
    
    def spike_test(self, spike_users: int = 10000, duration_seconds: int = 30,
                   share_code_ratio: float = 0.3) -> TestSummary:
        """
        å³°å€¼æµ‹è¯• - ç¬é—´è¾¾åˆ°10000å¹¶å‘
        
        Args:
            spike_users: å³°å€¼å¹¶å‘ç”¨æˆ·æ•°
            duration_seconds: å³°å€¼æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            share_code_ratio: ä½¿ç”¨åˆ†äº«ç çš„è¯·æ±‚æ¯”ä¾‹
            
        Returns:
            TestSummary: æµ‹è¯•æ±‡æ€»
        """
        logger.info(f"âš¡ å¼€å§‹å³°å€¼æµ‹è¯•: ç¬é—´è¾¾åˆ°{spike_users:,}å¹¶å‘ç”¨æˆ·")
        logger.info(f"å³°å€¼æŒç»­æ—¶é—´: {duration_seconds}ç§’")
        
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        with ThreadPoolExecutor(max_workers=spike_users) as executor:
            futures = []
            
            # ç¬é—´æäº¤æ‰€æœ‰è¯·æ±‚
            for i in range(spike_users):
                use_share_code = random.random() < share_code_ratio
                share_code = random.choice(self._generate_share_codes()) if use_share_code else None
                user_id = f"spike_user_{i:05d}"
                
                future = executor.submit(
                    self._make_request, user_id, share_code
                )
                futures.append(future)
            
            logger.info(f"å·²æäº¤ {spike_users:,} ä¸ªå³°å€¼è¯·æ±‚ï¼Œç­‰å¾…å®Œæˆ...")
            
            # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆæˆ–è¶…æ—¶
            completed = 0
            for future in as_completed(futures):
                result = future.result()
                self._record_result(result)
                completed += 1
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                if time.time() > end_time:
                    logger.warning("âš ï¸ å³°å€¼æµ‹è¯•è¶…æ—¶ï¼Œå¼ºåˆ¶ç»“æŸ")
                    break
                
                # æ¯1000ä¸ªå®Œæˆæ˜¾ç¤ºè¿›åº¦
                if completed % 1000 == 0:
                    logger.info(f"å·²å®Œæˆ {completed:,} ä¸ªå³°å€¼è¯·æ±‚...")
        
        total_time = time.time() - start_time
        return self._calculate_summary(total_time)
    
    def _calculate_summary(self, total_time: float) -> TestSummary:
        """è®¡ç®—æµ‹è¯•æ±‡æ€»æ•°æ®"""
        if not self.results:
            return TestSummary(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {}, {})
        
        successful = [r for r in self.results if r.success]
        failed = [r for r in self.results if not r.success]
        
        response_times = [r.response_time for r in self.results]
        response_times.sort()
        
        total_requests = len(self.results)
        successful_requests = len(successful)
        failed_requests = len(failed)
        
        avg_response_time = statistics.mean(response_times) if response_times else 0
        min_response_time = min(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        
        # è®¡ç®—ç™¾åˆ†ä½æ•°
        p95_index = int(len(response_times) * 0.95)
        p99_index = int(len(response_times) * 0.99)
        
        p95_response_time = response_times[p95_index] if p95_index < len(response_times) else 0
        p99_response_time = response_times[p99_index] if p99_index < len(response_times) else 0
        
        requests_per_second = total_requests / total_time if total_time > 0 else 0
        success_rate = successful_requests / total_requests if total_requests > 0 else 0
        
        # é”™è¯¯åˆ†å¸ƒç»Ÿè®¡
        error_distribution = {}
        for result in failed:
            error_type = f"HTTP_{result.status_code}" if result.status_code > 0 else "Network_Error"
            error_distribution[error_type] = error_distribution.get(error_type, 0) + 1
        
        # å“åº”æ—¶é—´åˆ†å¸ƒç»Ÿè®¡
        response_time_distribution = {
            "0-100ms": len([r for r in response_times if r < 0.1]),
            "100-500ms": len([r for r in response_times if 0.1 <= r < 0.5]),
            "500ms-1s": len([r for r in response_times if 0.5 <= r < 1.0]),
            "1-3s": len([r for r in response_times if 1.0 <= r < 3.0]),
            "3-5s": len([r for r in response_times if 3.0 <= r < 5.0]),
            "5s+": len([r for r in response_times if r >= 5.0])
        }
        
        return TestSummary(
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            avg_response_time=avg_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=requests_per_second,
            success_rate=success_rate,
            error_distribution=error_distribution,
            response_time_distribution=response_time_distribution
        )
    
    def print_summary(self, summary: TestSummary, test_name: str = "æµ‹è¯•"):
        """æ‰“å°æµ‹è¯•æ±‡æ€»ä¿¡æ¯"""
        print(f"\n{'='*60}")
        print(f"{test_name} ç»“æœæ±‡æ€»")
        print(f"{'='*60}")
        print(f"æ€»è¯·æ±‚æ•°: {summary.total_requests:,}")
        print(f"æˆåŠŸè¯·æ±‚: {summary.successful_requests:,}")
        print(f"å¤±è´¥è¯·æ±‚: {summary.failed_requests:,}")
        print(f"æˆåŠŸç‡: {summary.success_rate:.2%}")
        print(f"å¹³å‡å“åº”æ—¶é—´: {summary.avg_response_time:.3f}ç§’")
        print(f"æœ€å°å“åº”æ—¶é—´: {summary.min_response_time:.3f}ç§’")
        print(f"æœ€å¤§å“åº”æ—¶é—´: {summary.max_response_time:.3f}ç§’")
        print(f"95%å“åº”æ—¶é—´: {summary.p95_response_time:.3f}ç§’")
        print(f"99%å“åº”æ—¶é—´: {summary.p99_response_time:.3f}ç§’")
        print(f"æ¯ç§’è¯·æ±‚æ•°: {summary.requests_per_second:.2f}")
        
        if summary.error_distribution:
            print(f"\né”™è¯¯åˆ†å¸ƒ:")
            for error_type, count in summary.error_distribution.items():
                print(f"  {error_type}: {count}")
        
        if summary.response_time_distribution:
            print(f"\nå“åº”æ—¶é—´åˆ†å¸ƒ:")
            for time_range, count in summary.response_time_distribution.items():
                print(f"  {time_range}: {count}")
        
        print(f"{'='*60}")
    
    def export_results(self, filename: str = None):
        """å¯¼å‡ºæµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"new_info_load_test_results_{timestamp}.json"
        
        export_data = {
            'test_info': {
                'interface': 'new_info',
                'base_url': self.base_url,
                'timestamp': datetime.now().isoformat(),
                'total_results': len(self.results)
            },
            'results': [
                {
                    'url': r.url,
                    'method': r.method,
                    'status_code': r.status_code,
                    'response_time': r.response_time,
                    'success': r.success,
                    'error_message': r.error_message,
                    'timestamp': r.timestamp,
                    'user_id': r.user_id,
                    'share_code': r.share_code
                }
                for r in self.results
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æµ‹è¯•ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Mall new_infoæ¥å£10000å¹¶å‘å‹åŠ›æµ‹è¯•å·¥å…·')
    parser.add_argument('--url', required=True, help='APIåŸºç¡€URL (ä¾‹å¦‚: http://localhost:8000/api)')
    parser.add_argument('--tokens', nargs='+', help='è®¤è¯tokenåˆ—è¡¨ï¼Œç”¨äºæ¨¡æ‹Ÿä¸åŒç”¨æˆ·')
    parser.add_argument('--test-type', choices=['concurrent', 'stress', 'spike'], 
                       default='concurrent', help='æµ‹è¯•ç±»å‹')
    parser.add_argument('--users', type=int, default=10000, help='å¹¶å‘ç”¨æˆ·æ•°')
    parser.add_argument('--requests', type=int, default=50000, help='æ€»è¯·æ±‚æ•°')
    parser.add_argument('--share-ratio', type=float, default=0.3, help='åˆ†äº«ç ä½¿ç”¨æ¯”ä¾‹')
    parser.add_argument('--export', action='store_true', help='å¯¼å‡ºæµ‹è¯•ç»“æœ')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ Mall new_infoæ¥å£å‹åŠ›æµ‹è¯•")
    print(f"ğŸ”— APIåœ°å€: {args.url}")
    print(f"ğŸ“‹ æµ‹è¯•ç±»å‹: {args.test_type}")
    print(f"ğŸ‘¥ å¹¶å‘ç”¨æˆ·æ•°: {args.users:,}")
    print(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {args.requests:,}")
    print(f"ğŸ”— åˆ†äº«ç æ¯”ä¾‹: {args.share_ratio:.1%}")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    try:
        tester = NewInfoLoadTester(args.url, args.tokens)
        print("âœ… æµ‹è¯•å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    try:
        if args.test_type == 'concurrent':
            result = tester.concurrent_test(
                concurrent_users=args.users,
                total_requests=args.requests,
                share_code_ratio=args.share_ratio
            )
            tester.print_summary(result, f"10000å¹¶å‘æµ‹è¯• - new_infoæ¥å£")
            
        elif args.test_type == 'stress':
            results = tester.stress_test(
                initial_users=1000,
                max_users=args.users,
                step_users=1000,
                step_duration=60,
                share_code_ratio=args.share_ratio
            )
            
            for i, summary in enumerate(results):
                tester.print_summary(summary, f"å‹åŠ›æµ‹è¯• - æ­¥éª¤ {i+1}")
                
        elif args.test_type == 'spike':
            result = tester.spike_test(
                spike_users=args.users,
                duration_seconds=30,
                share_code_ratio=args.share_ratio
            )
            tester.print_summary(result, f"å³°å€¼æµ‹è¯• - {args.users:,}å¹¶å‘ç”¨æˆ·")
        
        # å¯¼å‡ºç»“æœ
        if args.export:
            filename = f"new_info_{args.test_type}_{args.users}users_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            tester.export_results(filename)
            print(f"ğŸ“ æµ‹è¯•ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
